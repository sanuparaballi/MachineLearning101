{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.syracuse.edu/wp-content/themes/g6-carbon/img/syracuse-university-seal.svg?ver=6.3.9\" style=\"width: 300px;\"/>\n",
    "\n",
    "# Evolutionary Machine Learning - ML101\n",
    "## CIS600 - Homework 1\n",
    "## Author - Sanup Araballi\n",
    "### Genetics Algorithm Approach\n",
    "##### Hello World!\n",
    "\n",
    "###### Disclaimer: \n",
    "1. I have used Titanic Dataset. \n",
    "2. I have referred to the links provided by Subodh Kalia on Blackboard and have based my solutions on them.\n",
    "3. The graphs are referred from official python/keras website\n",
    "4. The design of the models, playing around with the layers and the shape of layers and node along with data preparation part is by me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolutionary Machine Learning - Using Package Geneticalgs\n",
    "from geneticalgs import BinaryGA, RealGA, DiffusionGA, MigrationGA\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras as ks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "\n",
    "# For Plotting Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib.pylab import rcParams\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First get the data from the files and prepare them to be extracted as feature set. Drop the columns which are not adding value to feature set and clean the data to keep only numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and prepare data\n",
    "ttd_train = pd.read_csv('Train.csv', header=0)\n",
    "ttd_test = pd.read_csv('Test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch Embarked\n",
       "0       3    male  34.5      0      0        Q\n",
       "1       3  female  47.0      1      0        S\n",
       "2       2    male  62.0      0      0        Q\n",
       "3       3    male  27.0      0      0        S\n",
       "4       3  female  22.0      1      1        S"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttd_train.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], 1, inplace=True)\n",
    "ttd_test.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], 1, inplace=True)\n",
    "ttd_train.head()\n",
    "ttd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Routines to convert strings to numberical values\n",
    "#I am randomizing the values to a range here with the hopes that\n",
    "#the contiguous values will help in better training of the neural network\n",
    "def convGender(gen):\n",
    "    if gen == 'female':\n",
    "        return 0\n",
    "    elif gen == 'male' :\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def convEmbarked(emb):\n",
    "    if emb == 'S':\n",
    "        return 0\n",
    "    elif emb == 'C':\n",
    "        return 1\n",
    "    elif emb == 'Q':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch  Embarked\n",
       "0         0       3    1  22.0      1      0         0\n",
       "1         1       1    0  38.0      1      0         1\n",
       "2         1       3    0  26.0      0      0         0\n",
       "3         1       1    0  35.0      1      0         0\n",
       "4         0       3    1  35.0      0      0         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the rows where age has no value. Call the routines to convert strings to numerical values\n",
    "ttd_train.dropna(subset=['Age'], inplace=True)\n",
    "ttd_test.dropna(subset=['Age'], inplace=True)\n",
    "\n",
    "ttd_train['Embarked'] = ttd_train.apply(lambda row: convEmbarked(row['Embarked']), axis=1)\n",
    "ttd_train['Sex'] = ttd_train.apply(lambda row: convGender(row['Sex']), axis=1)\n",
    "ttd_test['Embarked'] = ttd_test.apply(lambda row: convEmbarked(row['Embarked']), axis=1)\n",
    "ttd_test['Sex'] = ttd_test.apply(lambda row: convGender(row['Sex']), axis=1)\n",
    "\n",
    "ttd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  Embarked\n",
       "0       3    1  34.5      0      0         2\n",
       "1       3    0  47.0      1      0         0\n",
       "2       2    1  62.0      0      0         2\n",
       "3       3    1  27.0      0      0         0\n",
       "4       3    0  22.0      1      1         0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttd_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the given training data into train and test data to be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the given data into x and y along with training and test data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = ttd_train.drop('Survived', axis=1)\n",
    "y = ttd_train['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network model based on the geneticalgs library and use the parameters to play around with settings for improving accuracy\n",
    "\n",
    "### Few points to be noted:\n",
    "1. Tried running it for various number of generations ranging from 10 to 5000. For 5000 generations, had left the laptop running for the whole night, but it still didn't finish.\n",
    "2. Since TensorFlow on my machine is CPU based, I am putting down the generations to 100. Can be changed depending on the machine used.\n",
    "3. I have played around with mutation probability as well. 0.1 seems to be ideal for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA standard settings\n",
    "generation_num = 100\n",
    "population_size = 24\n",
    "elitism = True\n",
    "selection = 'rank'\n",
    "tournament_size = None # in case of tournament selection\n",
    "mut_type = 1\n",
    "mut_prob = 0.1\n",
    "cross_type = 1\n",
    "cross_prob = 0.95\n",
    "optim = 'min' # minimize or maximize a fitness value\n",
    "interval = (-1, 1)\n",
    "\n",
    "# Migration GA settings\n",
    "period = 5\n",
    "migrant_num = 10\n",
    "cloning = True\n",
    "\n",
    "#Function used to get random floating point numbers for initial weights\n",
    "def rand(x):\n",
    "    return abs(x*(math.sin(x/11)/5 + math.sin(x/110)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have build the model as a convex shape instead of a convergence from the 1st hidden layer. This has helped me to improve accuracy significantly and consistently(70% and above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                416       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Model\n",
    "# Following the trials on back-propogation, I have adopted convex shape of neural network here as well.\n",
    "# The accuracy has improved significantly!\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 6, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Not using model.compile - instead setting weights manually\n",
    "#model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the initial weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially thought the I would have to initialize weights, but this seem to make no difference. \n",
    "#Check the effects later.\n",
    "x1 = list(range(1000))\n",
    "y1 = [rand(elem) for elem in x1]\n",
    "\n",
    "a = np.array(y1[0:72]).reshape(6,12)\n",
    "b = np.array(y1[72:84])\n",
    "c = np.array(y1[84:468]).reshape(12,32)\n",
    "d = np.array(y1[468:500])\n",
    "e = np.array(y1[500:756]).reshape(32,8)\n",
    "f = np.array(y1[756:764])\n",
    "g = np.array(y1[764:772]).reshape(8,1)\n",
    "h = np.array(y1[772:773])\n",
    "\n",
    "model.layers[0].set_weights([a,b])\n",
    "model.layers[1].set_weights([c,d])\n",
    "model.layers[2].set_weights([e,f])\n",
    "model.layers[3].set_weights([g,h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 2.72475686e-02 1.08688869e-01 2.43423387e-01\n",
      "  4.29962605e-01 6.66248441e-01 9.49678540e-01 1.27713871e+00\n",
      "  1.64504123e+00 2.04937005e+00 2.48573017e+00 2.94940376e+00]\n",
      " [3.43540859e+00 3.93856215e+00 4.45354652e+00 4.97497845e+00\n",
      "  5.49747658e+00 6.01573515e+00 6.52459145e+00 7.01909733e+00\n",
      "  7.49458551e+00 7.94673491e+00 8.37163353e+00 8.76583672e+00]\n",
      " [9.12641621e+00 9.45101452e+00 9.73788261e+00 9.98591423e+00\n",
      "  1.01946802e+01 1.03644419e+01 1.04961720e+01 1.05915546e+01\n",
      "  1.06529846e+01 1.06835585e+01 1.06870546e+01 1.06679029e+01]\n",
      " [1.06311560e+01 1.05824432e+01 1.05279207e+01 1.04742155e+01\n",
      "  1.04283657e+01 1.03977451e+01 1.03899975e+01 1.04129524e+01\n",
      "  1.04745455e+01 1.05827341e+01 1.07454138e+01 1.09703226e+01]\n",
      " [1.12649622e+01 1.16365051e+01 1.20917110e+01 1.26368437e+01\n",
      "  1.32775917e+01 1.40189924e+01 1.48653641e+01 1.58202372e+01\n",
      "  1.68863029e+01 1.80653591e+01 1.93582706e+01 2.07649326e+01]\n",
      " [2.22842503e+01 2.39141254e+01 2.56514454e+01 2.74920902e+01\n",
      "  2.94309559e+01 3.14619656e+01 3.35781174e+01 3.57715263e+01\n",
      "  3.80334663e+01 4.03544617e+01 4.27243347e+01 4.51322975e+01]] [47.567036 50.016815 52.469566 54.913002 57.33473  59.722355 62.063606\n",
      " 64.34644  66.55918  68.690605 70.73008  72.667656]\n",
      "(6, 12)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#Checking values to help in debugging\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]\n",
    "print(weights, biases)\n",
    "print(np.shape(weights))\n",
    "print(np.shape(biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error function which will be used by the GA and update the weights and biases inside it based on the value of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the error function to be called by GA.\n",
    "#Inside this function, prepare and set weights as well based on the input value of X.\n",
    "\n",
    "def err_funct(x):\n",
    "\n",
    "    a = np.array(x[0:72]).reshape(6,12)\n",
    "    b = np.array(x[72:84])\n",
    "    c = np.array(x[84:468]).reshape(12,32)\n",
    "    d = np.array(x[468:500])\n",
    "    e = np.array(x[500:756]).reshape(32,8)\n",
    "    f = np.array(x[756:764])\n",
    "    g = np.array(x[764:772]).reshape(8,1)\n",
    "    h = np.array(x[772:773])\n",
    "    \n",
    "    model.layers[0].set_weights([a,b])\n",
    "    model.layers[1].set_weights([c,d])\n",
    "    model.layers[2].set_weights([e,f])\n",
    "    model.layers[3].set_weights([g,h])\n",
    "    \n",
    "    y_predict = model.predict(x_train)\n",
    "\n",
    "#Addition of this correction to predicted values make the results skewed towards only one result. \n",
    "#No rectification required for each generation. Hence commenting\n",
    "#    i = 0\n",
    "#    while i < len(y_predict):\n",
    "#        if y_predict[i][0] < 0.5:\n",
    "#            y_predict[i][0] = 0\n",
    "#        else:\n",
    "#            y_predict[i][0] = 1\n",
    "#        i += 1    \n",
    "\n",
    "# Calculate the RMSE score if you opt to minimize fitness in GA\n",
    "#Using the library function is not suitable here since we are not rectifying the results to 0s and 1s\n",
    "    #rmse = np.sqrt(mean_squared_error(y_train, y_predict))\n",
    "    #print('Validation RMSE: ', rmse,' ')\n",
    "    \n",
    "        \n",
    "    # Calculate the accuracy score if you opt to maximize fitness in GA\n",
    "    #acc = accuracy_score(y_train, y_predict)\n",
    "    #print('Accuracy Score: ', acc, '\\n')\n",
    "    \n",
    "    y_predict=y_predict.flatten()\n",
    "    rmse = np.sum(np.square(y_predict - y_train))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the GA and print the best solution's weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoke the genetic algorithm using RealGA\n",
    "sga = RealGA(err_funct, optim=optim, elitism=elitism, selection=selection,\n",
    "            mut_type=mut_type, mut_prob=mut_prob, \n",
    "            cross_type=cross_type, cross_prob=cross_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.60174658, -0.22320406, -0.38178914,  0.96291318,  0.99592542,\n",
       "         0.12681755,  0.50599692, -0.52941549, -0.24299734,  0.38594565,\n",
       "         0.37451509,  0.56189971, -0.36481717, -0.95765668, -0.01896719,\n",
       "         0.66363964,  0.42294332,  0.23546125,  0.27667578, -0.6752717 ,\n",
       "        -0.96738569, -0.87319744,  0.38122256, -0.08821676, -0.03273516,\n",
       "         0.27745682, -0.52488576, -0.37010361, -0.12601151, -0.13058154,\n",
       "        -0.11522147, -0.48025143,  0.51160219,  0.11752907,  0.52675053,\n",
       "        -0.19344119, -0.31787761, -0.80476078, -0.5361662 ,  0.0517012 ,\n",
       "         0.25821366,  0.74537624,  0.51226439, -0.79440631,  0.4757434 ,\n",
       "         0.49333542,  0.36223739,  0.46752747,  0.88991314, -0.04391341,\n",
       "         0.13005673,  0.46870627,  0.56485511, -0.03074585, -0.26762041,\n",
       "        -0.07456385,  0.58386611, -0.40301249,  0.37581218,  0.27610278,\n",
       "         0.95887508,  0.06434393, -0.04851221,  0.14197995,  0.72810346,\n",
       "        -0.73809751,  0.49540745, -0.33853785,  0.95371906,  0.8056694 ,\n",
       "        -0.17337448, -0.06087676,  0.69122091,  0.69934436,  0.39695725,\n",
       "         0.98411505, -0.46017618,  0.60451488, -0.16016496, -0.14153755,\n",
       "         0.50929518, -0.27835708, -0.18620031, -0.7722615 , -0.99123469,\n",
       "        -0.7364914 , -0.85836468, -0.86776604,  0.92957528, -0.49050528,\n",
       "         0.29553801, -0.28343091,  0.36716794, -0.73173311, -0.19482176,\n",
       "        -0.20992982, -0.80738013, -0.61342379, -0.84767292,  0.9899493 ,\n",
       "         0.37089863,  0.07445728,  0.81505873, -0.63882662,  0.32597218,\n",
       "         0.96654288,  0.04212321, -0.84052323,  0.88734233, -0.17316128,\n",
       "        -0.55530208,  0.56982178,  0.33895124,  0.7809941 ,  0.82104737,\n",
       "         0.31631742,  0.82381915, -0.66424259, -0.35168632,  0.81991992,\n",
       "         0.49481822, -0.22053644, -0.04709943,  0.97490073,  0.32823542,\n",
       "        -0.19497342,  0.2060016 ,  0.43357924,  0.26097869,  0.54295389,\n",
       "        -0.69445204,  0.06589507, -0.75505339, -0.03433822, -0.28617873,\n",
       "        -0.70406649, -0.94961836,  0.99177926, -0.0831697 , -0.14832865,\n",
       "         0.21922334,  0.51111955, -0.14689737, -0.10726951, -0.18128807,\n",
       "        -0.49010355,  0.4530867 , -0.60812227,  0.15954439,  0.3001436 ,\n",
       "        -0.25462319, -0.27133677, -0.21172723,  0.19904182,  0.31838473,\n",
       "        -0.21055226,  0.33828233,  0.4283571 ,  0.0479993 ,  0.29698319,\n",
       "         0.10824046,  0.19841998, -0.74428561, -0.11517957, -0.73544004,\n",
       "         0.14165108,  0.62184385,  0.94956868,  0.79974923,  0.80327291,\n",
       "        -0.34586997, -0.40277487,  0.78200906, -0.47706484,  0.15570577,\n",
       "         0.09896624, -0.1291773 ,  0.3808419 , -0.3886061 ,  0.36957761,\n",
       "         0.63876888, -0.83066075,  0.43288907, -0.60141917,  0.9595158 ,\n",
       "        -0.12002026, -0.91900737,  0.86839779,  0.10118449, -0.1605986 ,\n",
       "         0.18250991,  0.2162416 ,  0.33815219,  0.55044334,  0.93014417,\n",
       "         0.024927  ,  0.81907569, -0.12370532, -0.60681269,  0.28772309,\n",
       "        -0.42670424, -0.19873618,  0.86141623, -0.79310293,  0.35989802,\n",
       "         0.22266086, -0.95699771, -0.77991737,  0.7933604 , -0.63947008,\n",
       "        -0.85564932, -0.78652159,  0.9897448 ,  0.47432095, -0.09359958,\n",
       "        -0.22537018, -0.9332531 , -0.67514841, -0.47093495, -0.68327016,\n",
       "         0.24240518,  0.21458248,  0.38571471, -0.81670263,  0.44213774,\n",
       "         0.73103624, -0.99305129, -0.87385266, -0.07659136, -0.71410703,\n",
       "         0.07037031, -0.10782944,  0.7605424 , -0.71827461, -0.84901916,\n",
       "        -0.07841661, -0.41891211, -0.47812752, -0.8544287 , -0.89680405,\n",
       "         0.61793061, -0.3565662 , -0.21774554,  0.36409279,  0.60096675,\n",
       "         0.61478695,  0.55271154, -0.07990046,  0.40425831, -0.63783751,\n",
       "         0.16237908, -0.98816219, -0.93253599, -0.75862189, -0.70563683,\n",
       "        -0.80066493, -0.10571587,  0.70927528, -0.85975293,  0.1702756 ,\n",
       "         0.43440682, -0.82939074, -0.2689456 , -0.97654448, -0.58403954,\n",
       "         0.94311795,  0.30423482, -0.42489913, -0.56232038, -0.88021741,\n",
       "         0.15379785, -0.50022609,  0.0272558 , -0.75219075,  0.69066467,\n",
       "        -0.08530078,  0.37772154,  0.32979704, -0.87865499, -0.07401304,\n",
       "         0.04876638, -0.32735696,  0.55562765,  0.69260336, -0.14073811,\n",
       "         0.12840911,  0.98923163,  0.93821382,  0.70235481, -0.44284672,\n",
       "        -0.63101256,  0.85238194,  0.92292874, -0.00144428, -0.03220349,\n",
       "         0.72214948, -0.64819161,  0.68069479, -0.55999795,  0.68185745,\n",
       "        -0.40154735, -0.98412616, -0.41209673,  0.13190398,  0.34249892,\n",
       "        -0.27192395,  0.59018094,  0.47846005, -0.57783508, -0.13640768,\n",
       "         0.18178877,  0.86045802,  0.6186196 ,  0.86640955,  0.40642878,\n",
       "        -0.29281469, -0.32952758, -0.90448266, -0.73309197,  0.14719347,\n",
       "        -0.67344549, -0.2726008 , -0.30716857,  0.87295286,  0.12427379,\n",
       "         0.70002434, -0.83794902, -0.74065802, -0.29492186,  0.80425156,\n",
       "         0.67819355,  0.10974307,  0.65904251, -0.4788145 ,  0.569342  ,\n",
       "        -0.88099441,  0.36155558,  0.25094816,  0.69180889, -0.47218652,\n",
       "        -0.13461286, -0.87455497,  0.89911319,  0.17684523, -0.28674145,\n",
       "         0.28124303,  0.69610442, -0.42869409, -0.13439613,  0.78697623,\n",
       "        -0.71774765,  0.07582943,  0.94329289,  0.32970438,  0.52441911,\n",
       "        -0.9038005 ,  0.54768319,  0.46204847,  0.52002722,  0.65952628,\n",
       "        -0.8362348 , -0.91751086,  0.63401202, -0.41136516,  0.19182123,\n",
       "        -0.20009337, -0.5243203 ,  0.68893829,  0.11540254,  0.62283962,\n",
       "         0.70543297, -0.22258839, -0.37892139, -0.95216083,  0.4213457 ,\n",
       "         0.76764497,  0.65903051, -0.45825389, -0.6841039 , -0.5087202 ,\n",
       "         0.39998892,  0.9832931 , -0.79173972,  0.54904036,  0.02193589,\n",
       "         0.24183051,  0.47485306,  0.25601324,  0.70403142, -0.80807447,\n",
       "         0.8926939 ,  0.96744178,  0.91331122, -0.32957672,  0.96648265,\n",
       "         0.20504644,  0.40159975, -0.77281595, -0.56167242,  0.54099811,\n",
       "        -0.40215218, -0.68521411, -0.37759757, -0.60733715,  0.93885866,\n",
       "        -0.25052786, -0.75261451,  0.78984007, -0.22043128,  0.71822743,\n",
       "        -0.40575001, -0.03934289,  0.49068342, -0.03224834, -0.00274218,\n",
       "        -0.61550327, -0.13062941,  0.22668303,  0.87844837, -0.79911851,\n",
       "         0.87267801,  0.3263082 ,  0.33476398,  0.05281926,  0.18197569,\n",
       "        -0.44963889, -0.50153816, -0.2895701 ,  0.40601818, -0.06629879,\n",
       "         0.04155647,  0.00182829,  0.44145904, -0.48455332,  0.21468725,\n",
       "        -0.08944308,  0.89306896, -0.59323918, -0.41048381,  0.41857784,\n",
       "        -0.55477876, -0.12559447, -0.98636312,  0.47622494,  0.67514497,\n",
       "         0.51353373, -0.95909495, -0.54397148,  0.00788776, -0.22692552,\n",
       "         0.20582115,  0.30472765,  0.39790333, -0.18286988,  0.00473172,\n",
       "        -0.14886383,  0.00514807,  0.18377151,  0.63084198, -0.43027624,\n",
       "         0.65692076, -0.50555725, -0.56697628, -0.48446354,  0.86714612,\n",
       "        -0.8305695 ,  0.54739133,  0.84930336, -0.92083753, -0.12393459,\n",
       "         0.58337265, -0.24918171, -0.98704195,  0.217915  , -0.25067819,\n",
       "         0.76653758, -0.92943089, -0.36574915, -0.97759985, -0.42297625,\n",
       "         0.5257761 , -0.72485943,  0.86223831,  0.1679944 , -0.09691891,\n",
       "         0.64068378,  0.1811189 ,  0.69936223,  0.96184853, -0.27104021,\n",
       "         0.12945025,  0.34773956, -0.02554392, -0.37252117, -0.82647962,\n",
       "         0.57759401,  0.58520901,  0.19713567,  0.70641302, -0.32661948,\n",
       "        -0.47580969, -0.28708575, -0.39667448, -0.83921942,  0.91215422,\n",
       "         0.8405675 , -0.12320458, -0.97075506,  0.87872198, -0.61259203,\n",
       "        -0.86484258,  0.17523064,  0.61119214,  0.63889914,  0.70273928,\n",
       "        -0.29639114,  0.23065023, -0.21888321, -0.73640463, -0.61081032,\n",
       "         0.50679751, -0.9764971 , -0.45791192,  0.40608032, -0.9356229 ,\n",
       "         0.01800121, -0.57179554,  0.52361305,  0.07937773,  0.5356899 ,\n",
       "         0.38710366, -0.76919631, -0.1634151 , -0.47994425, -0.74259788,\n",
       "         0.86742193,  0.57610079, -0.90373487, -0.66023228,  0.65674482,\n",
       "        -0.00762947,  0.61106714, -0.49889512,  0.89106586,  0.67389426,\n",
       "        -0.5754186 , -0.49041633, -0.84132769, -0.88674995,  0.02273659,\n",
       "        -0.06093921,  0.51998554,  0.69562602, -0.41585867,  0.00870014,\n",
       "         0.21988248,  0.9258063 , -0.85807889,  0.88117233, -0.71138482,\n",
       "        -0.11800001,  0.6009541 ,  0.11360508, -0.81892512, -0.25295152,\n",
       "        -0.4910431 , -0.55713642,  0.41663816, -0.80403236,  0.02080115,\n",
       "        -0.56690707, -0.98843396,  0.1372896 ,  0.61684207,  0.03899915,\n",
       "        -0.02869025,  0.54639227, -0.73212715,  0.11896805, -0.15532573,\n",
       "         0.97101475,  0.29866811, -0.96666725,  0.35669233,  0.54854479,\n",
       "         0.84035635,  0.68678054,  0.16962993, -0.78416307, -0.03546246,\n",
       "        -0.05616282,  0.8453936 , -0.09506155,  0.84454606, -0.63071065,\n",
       "        -0.51429864, -0.5246443 ,  0.44001413, -0.3197375 , -0.38259032,\n",
       "         0.65237775, -0.224307  , -0.63457798,  0.62381429, -0.02356634,\n",
       "        -0.26097618, -0.32663886, -0.94182829,  0.015191  ,  0.71858128,\n",
       "         0.35787912, -0.58979113,  0.1245352 , -0.09834204,  0.02099529,\n",
       "         0.08879382,  0.49856188, -0.87673236, -0.80157379, -0.66748601,\n",
       "        -0.72601006,  0.51199928,  0.8617226 ,  0.82942264,  0.26127405,\n",
       "        -0.54363536, -0.09219572, -0.82320648,  0.9689123 ,  0.31724169,\n",
       "        -0.48106895,  0.2262576 ,  0.22746691,  0.54198748,  0.50960095,\n",
       "        -0.97087952, -0.76332451,  0.36730802, -0.48757953, -0.76188137,\n",
       "        -0.58902793, -0.33349862, -0.91337348, -0.55214331, -0.44852698,\n",
       "         0.66134621,  0.84596542,  0.76338578, -0.30398627,  0.95457371,\n",
       "        -0.64401475, -0.43601055,  0.77132162, -0.59904682, -0.67977328,\n",
       "         0.50067201, -0.11120505,  0.34399104,  0.73075365,  0.15701308,\n",
       "         0.82135959,  0.89242967,  0.03122139, -0.51175152, -0.25804079,\n",
       "         0.40042582,  0.27317073,  0.33337489, -0.50988545, -0.72884072,\n",
       "        -0.02898406,  0.98312058, -0.50629203,  0.17448094,  0.22535952,\n",
       "         0.79691031,  0.11501856, -0.08882908, -0.99761278, -0.23702705,\n",
       "         0.61653823,  0.6112222 , -0.68265878,  0.83323471, -0.04716973,\n",
       "         0.12830311, -0.28873695, -0.36835524,  0.70528151,  0.95921424,\n",
       "        -0.68914983,  0.3980477 , -0.81012688, -0.92158978,  0.10427036,\n",
       "         0.96924414, -0.12716518,  0.39488878, -0.98852988, -0.5016552 ,\n",
       "        -0.64079568, -0.98474928, -0.4532697 ,  0.50215646, -0.29266773,\n",
       "        -0.94989655,  0.94069307,  0.55808996, -0.42273772,  0.38544064,\n",
       "        -0.50411757, -0.12329941,  0.48600545, -0.89129122, -0.09126803,\n",
       "         0.28501831, -0.52763793, -0.8603301 ,  0.36035662,  0.5758664 ,\n",
       "        -0.22828609, -0.92492946, -0.89458279,  0.84216954,  0.36888415,\n",
       "        -0.58516442, -0.74217304, -0.87246318, -0.61478552,  0.92885207,\n",
       "         0.81962252, -0.41990131,  0.63388979,  0.42130127, -0.94354955,\n",
       "         0.3388601 , -0.12497759, -0.35561826, -0.08279845, -0.26776397,\n",
       "         0.63135525,  0.01200029, -0.67627817, -0.2619004 ,  0.91625705,\n",
       "        -0.88572463, -0.05690799, -0.9855747 , -0.06749196,  0.63492585,\n",
       "         0.53176768,  0.986477  , -0.40357174,  0.78538655, -0.73624061,\n",
       "        -0.06437738, -0.87046548,  0.44726516, -0.80407245, -0.48889711,\n",
       "         0.69468531,  0.27328263,  0.60622885, -0.51859788,  0.98408806,\n",
       "        -0.80217317, -0.65586276,  0.99781079, -0.25750748, -0.03612922,\n",
       "         0.19730282, -0.3147986 , -0.76737912]), 151.03728909635774)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the algorithm and print best solution\n",
    "sga.init_random_population(population_size, 773, interval)\n",
    "fitness_progress = sga.run(generation_num)\n",
    "\n",
    "sga.best_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the best solution matrix to predict the values on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149    0\n",
      "407    1\n",
      "53     1\n",
      "369    1\n",
      "818    0\n",
      "549    1\n",
      "85     1\n",
      "774    1\n",
      "100    0\n",
      "816    0\n",
      "781    1\n",
      "123    1\n",
      "690    1\n",
      "108    0\n",
      "258    1\n",
      "529    0\n",
      "296    0\n",
      "329    1\n",
      "886    0\n",
      "513    1\n",
      "71     0\n",
      "259    1\n",
      "852    0\n",
      "737    1\n",
      "225    0\n",
      "163    0\n",
      "282    0\n",
      "93     0\n",
      "111    0\n",
      "471    0\n",
      "      ..\n",
      "763    1\n",
      "317    0\n",
      "262    0\n",
      "66     1\n",
      "416    1\n",
      "436    0\n",
      "263    0\n",
      "556    1\n",
      "137    0\n",
      "199    0\n",
      "724    1\n",
      "508    0\n",
      "884    0\n",
      "772    0\n",
      "83     0\n",
      "261    1\n",
      "704    0\n",
      "570    1\n",
      "11     1\n",
      "703    0\n",
      "440    1\n",
      "844    0\n",
      "226    1\n",
      "662    0\n",
      "751    1\n",
      "356    1\n",
      "744    1\n",
      "872    0\n",
      "500    0\n",
      "829    1\n",
      "Name: Survived, Length: 72, dtype: int64\n",
      "[[0.39747846]\n",
      " [0.37533888]\n",
      " [0.39449427]\n",
      " [0.41797858]\n",
      " [0.3926503 ]\n",
      " [0.36912483]\n",
      " [0.37892964]\n",
      " [0.42005628]\n",
      " [0.38590267]\n",
      " [0.37920865]\n",
      " [0.39787915]\n",
      " [0.39986742]\n",
      " [0.39920253]\n",
      " [0.38988966]\n",
      " [0.41802725]\n",
      " [0.37221107]\n",
      " [0.373869  ]\n",
      " [0.41558194]\n",
      " [0.39130965]\n",
      " [0.40859136]\n",
      " [0.35535404]\n",
      " [0.4057851 ]\n",
      " [0.38714227]\n",
      " [0.41262385]\n",
      " [0.36958173]\n",
      " [0.36414805]\n",
      " [0.3636748 ]\n",
      " [0.3677202 ]\n",
      " [0.3742219 ]\n",
      " [0.38988966]\n",
      " [0.37064618]\n",
      " [0.37330353]\n",
      " [0.40302095]\n",
      " [0.38737243]\n",
      " [0.38285422]\n",
      " [0.38976818]\n",
      " [0.39264905]\n",
      " [0.4074337 ]\n",
      " [0.39921698]\n",
      " [0.39459077]\n",
      " [0.37397298]\n",
      " [0.36693487]\n",
      " [0.4216131 ]\n",
      " [0.39727065]\n",
      " [0.40470606]\n",
      " [0.39883184]\n",
      " [0.40155602]\n",
      " [0.3656153 ]\n",
      " [0.4026282 ]\n",
      " [0.41048932]\n",
      " [0.39999756]\n",
      " [0.39591876]\n",
      " [0.39767042]\n",
      " [0.37867698]\n",
      " [0.37409583]\n",
      " [0.3986063 ]\n",
      " [0.40251765]\n",
      " [0.36390454]\n",
      " [0.37086457]\n",
      " [0.396683  ]\n",
      " [0.40196928]\n",
      " [0.3826988 ]\n",
      " [0.4032265 ]\n",
      " [0.36414805]\n",
      " [0.38112456]\n",
      " [0.4015519 ]\n",
      " [0.3705863 ]\n",
      " [0.41516733]\n",
      " [0.3828565 ]\n",
      " [0.40309837]\n",
      " [0.36414805]\n",
      " [0.42994148]]\n",
      "[[35  5]\n",
      " [16 16]]\n",
      "Accuracy Score:  0.7083333333333334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using this best solution, predict results for the test data prepared\n",
    "best_weights = sga.best_solution[0]\n",
    "\n",
    "a = np.array(best_weights[0:72]).reshape(6,12)\n",
    "b = np.array(best_weights[72:84])\n",
    "c = np.array(best_weights[84:468]).reshape(12,32)\n",
    "d = np.array(best_weights[468:500])\n",
    "e = np.array(best_weights[500:756]).reshape(32,8)\n",
    "f = np.array(best_weights[756:764])\n",
    "g = np.array(best_weights[764:772]).reshape(8,1)\n",
    "h = np.array(best_weights[772:773])\n",
    "    \n",
    "model.layers[0].set_weights([a,b])\n",
    "model.layers[1].set_weights([c,d])\n",
    "model.layers[2].set_weights([e,f])\n",
    "model.layers[3].set_weights([g,h])\n",
    "\n",
    "y_test_p = model.predict(x_test)\n",
    "\n",
    "#To check results\n",
    "print(y_test)\n",
    "print(y_test_p)\n",
    "\n",
    "#Taking the arbitrary value as .4 here since most of the results seem to be grouped around that.\n",
    "i = 0\n",
    "while i < len(y_test_p):\n",
    "    if y_test_p[i][0] < .4:\n",
    "        y_test_p[i][0] = 0\n",
    "    else:\n",
    "        y_test_p[i][0] = 1\n",
    "    i += 1 \n",
    "\n",
    "#Print Confusion Matrix and Accuracy Score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_test_p)\n",
    "print(conf_matrix)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_p)\n",
    "print('Accuracy Score: ', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Fitness Progress(Mean Squared Error, in this case) over the generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113672400>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the fitness progress graph\n",
    "x1 = list(range(len(fitness_progress)))\n",
    "\n",
    "plt.plot(x1, fitness_progress, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
